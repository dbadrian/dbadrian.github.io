
@book{abdic_future_2015,
	title = {The {Future} of {Education}: {Trend} {Report} 2015},
	publisher = {Center for Digital Technology and Management},
	author = {Abdic, Irman and Adrian, David B and Borrow, Benjamin and Brander, Benedikt and Braun, Michael and Burger, Bastian and Frank, Fabian and Holzer, Alexander and Iwan, Stefan and Korbely, Stephanie and Kreil, Annika and Maier, Simon and Miksch, Michael and Nadeem, Asif and Poppek, Isabel and Rausch, Johannes and Ravindran, Aishwarya and Roos, Julian and Rüchardt, Valentin and Shafei, Ahmed and Strobel, Maximilian and Tischinger, Stefan and Wilk, Nathalie and Zaheer, Hassan},
	year = {2015},
}

@inproceedings{mukuta_weakly_2018,
	title = {Weakly supervised collective feature learning from curated media},
	url = {https://arxiv.org/abs/1802.04668},
	booktitle = {The {Thirty}-{Second} {AAAI} {Conference} on {Artificial} {Intelligence} ({AAAI}-18)},
	author = {Mukuta, Yusuke and Kimura, Akisato and Adrian, David B and Ghahramani, Zoubin},
	year = {2018},
}

@unpublished{weikersdorfer_event-based_2013,
	address = {Tutzing},
	type = {Poster},
	title = {Event-based {3D} {SLAM}, {Bernstein} {Sparks} {Workshop} on {NeuroEngineering}},
	author = {Weikersdorfer, D. and Adrian, D. and Conradt, J.},
	year = {2013},
}

@unpublished{kosiorek_efficient_2015,
	type = {"{Course} {Project} {Report}"},
	title = {An {Efficient} {Event}-{Based} {Optical} {Flow} {Implementation} in {C}/{C}++ and {CUDA}},
	url = {https://tum.neurocomputing.systems/fileadmin/w00bqs/www/publications/pp/2015SS-PP-RealTimeDVSOpticFlow.pdf},
	author = {Kosiorek, Adam and Adrian, David and Rausch, Johannes},
	year = {2015},
}

@inproceedings{weikersdorfer_event-based_2014,
	title = {Event-based {3D} {SLAM} with a depth-augmented dynamic vision sensor},
	url = {https://mediatum.ub.tum.de/doc/1192158/84014.pdf},
	booktitle = {Robotics and {Automation} ({ICRA}), 2014 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Weikersdorfer, David and Adrian, David B and Cremers, Daniel and Conradt, Jörg},
	year = {2014},
	pages = {359--364},
	file = {Weikersdorfer et al_2014_Event-based 3D SLAM with a depth-augmented dynamic vision sensor.pdf:/home/dbadrian/Zotero/storage/23TZRGY6/Weikersdorfer et al_2014_Event-based 3D SLAM with a depth-augmented dynamic vision sensor.pdf:application/pdf;Weikersdorfer et al. - 2014 - Event-based 3D SLAM with a depth-augmented dynamic.pdf:/home/dbadrian/Zotero/storage/LGLYHV24/Weikersdorfer et al. - 2014 - Event-based 3D SLAM with a depth-augmented dynamic.pdf:application/pdf},
}

@thesis{adrian_development_2013,
	address = {Munich},
	type = {Bachelor's {Thesis}},
	title = {Development of a {Depth}-{Augmented} {Dynamic} {Vision} {Sensor} for {3D} {SLAM}},
	url = {https://mediatum.ub.tum.de/doc/1192163/989741.pdf},
	school = {Technical University of Munich},
	author = {Adrian, David B.},
	year = {2013},
}

@mastersthesis{adrian_simple_2018,
	address = {Munich},
	type = {Masters's {Thesis}},
	title = {A {Simple} but {Universal} {Factorization} {Model} for {Embedding} {Knowledge} {Graphs}},
	school = {Technical University of Munich},
	author = {Adrian, David B.},
	year = {2018},
}

@inproceedings{adrian_efficient_2022,
	title = {Efficient and {Robust} {Training} of {Dense} {Object} {Nets} for {Multi}-{Object} {Robot} {Manipulation}},
	url = {https://arxiv.org/pdf/2206.12145.pdf},
	doi = {10.1109/ICRA46639.2022.9812274},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Adrian, David B. and Kupcsik, Andras Gabor and Spies, Markus and Neumann, Heiko},
	year = {2022},
	pages = {1562--1568},
}

@inproceedings{graf_learning_2023,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Learning {Dense} {Visual} {Descriptors} using {Image} {Augmentations} for {Robot} {Manipulation} {Tasks}},
	volume = {205},
	url = {https://proceedings.mlr.press/v205/graf23a.html},
	abstract = {We propose a self-supervised training approach for learning view-invariant dense visual descriptors using image augmentations. Unlike existing works, which often require complex datasets, such as registered RGBD sequences, we train on an unordered set of RGB images. This allows for learning from a single camera view, e.g., in an existing robotic cell with a fix-mounted camera. We create synthetic views and dense pixel correspondences using data augmentations. We find our descriptors are competitive to the existing methods, despite the simpler data recording and setup requirements. We show that training on synthetic correspondences provides descriptor consistency across a broad range of camera views. We compare against training with geometric correspondence from multiple views and provide ablation studies. We also show a robotic bin-picking experiment using descriptors learned from a fix-mounted camera for defining grasp preferences.},
	booktitle = {Proceedings of {The} 6th {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Graf, Christian and Adrian, David B. and Weil, Joshua and Gabriel, Miroslav and Schillinger, Philipp and Spies, Markus and Neumann, Heiko and Kupcsik, Andras Gabor},
	editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
	month = dec,
	year = {2023},
	pages = {871--880},
}
